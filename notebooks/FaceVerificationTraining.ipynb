{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.models import resnet50,ResNet50_Weights\n",
    "from PIL import Image\n",
    "import random, os\n",
    "import wandb\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"tsneplots\", exist_ok=True)\n",
    "os.makedirs(\"ROCplots\", exist_ok=True)\n",
    "\n",
    "print(\"Directories created or already exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 * 3\n",
    "LR = 2e-4\n",
    "DECAY = 1e-3\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 65\n",
    "FACTOR = 0.75\n",
    "EMB_DIM = 256\n",
    "THRESHOLD = 0.9\n",
    "ALPHA = 0.4\n",
    "INITIAL_ALPHA = 0.1\n",
    "FINAL_ALPHA = ALPHA\n",
    "N_EPOCHS_MARGIN = 49 # might need to change this to 75 or 100\n",
    "MARGIN = 0.5\n",
    "INITIAL_MARGIN = 1.0 \n",
    "PEAK_MARGIN = 0.6 # maybe make this a bit higher\n",
    "FINAL_MARGIN = 0.3 # maybe lower this\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "name = now.strftime(\"experiment_%d_%m_%H_%M\")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"face-verification\",\n",
    "    name=name,\n",
    "    config={\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": \"resnet50\",\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"loss\": \"hybrid triplet loss\",\n",
    "        'alpha': ALPHA,\n",
    "        'lr_scheduler': 'ReduceOnPlateau',\n",
    "        \"lr factor\": FACTOR,\n",
    "        \"margin\": MARGIN,\n",
    "        \"n_epochs_for_margin\":N_EPOCHS_MARGIN,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"dataset\": \"fullvggface2\",\n",
    "        \"emb_dim\": EMB_DIM,\n",
    "        'threshold': THRESHOLD,\n",
    "        \"augmentations\":\"agressive\",\n",
    "        \"margin_schedueler\": True,\n",
    "        \"cosine_sim_loss\": True,\n",
    "        'hard negative mining': True,\n",
    "        \"initial_margin\":INITIAL_MARGIN,\n",
    "        \"peak_margin\": PEAK_MARGIN,\n",
    "        \"final_margin\":FINAL_MARGIN,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_identities(root_dir):\n",
    "      all_entries = os.listdir(root_dir)\n",
    "      identities = []\n",
    "      for entry in all_entries:\n",
    "          full_path = os.path.join(root_dir,entry)\n",
    "          if os.path.isdir(full_path):\n",
    "              identities.append(entry)\n",
    "      return identities\n",
    "\n",
    "def get_portion_of_identities(identities,fraction):\n",
    "  n_identities = len(identities) \n",
    "\n",
    "  random.shuffle(identities)\n",
    "  cutoff = int(n_identities * fraction)\n",
    "  chosen_identities = identities[:cutoff]\n",
    "  return chosen_identities\n",
    "\n",
    "def build_label_to_images(root_dir,chosen_identities):\n",
    "  label_to_images = {}\n",
    "\n",
    "  for label in chosen_identities:\n",
    "      label_path = os.path.join(root_dir,label)\n",
    "      if os.path.isdir(label_path):\n",
    "          image_names = os.listdir(label_path)\n",
    "\n",
    "          image_paths = [os.path.join(label_path,image_name) for image_name in image_names]\n",
    "\n",
    "          if len(image_paths) >= 2:\n",
    "              label_to_images[label] = image_paths\n",
    "\n",
    "  return label_to_images\n",
    "def get_embedding(image_path, model, transform, device):\n",
    "    \"\"\"\n",
    "    Load an image, apply transforms, and compute its embedding.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device) \n",
    "    with torch.no_grad():\n",
    "        embedding = model(image)\n",
    "    return embedding.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FaceVerificationDataset(Dataset):\n",
    "    def __init__(self, label_to_imgs, transform=None):\n",
    "        self.label_to_imgs = label_to_imgs\n",
    "        self.transform = transform\n",
    "        self.labels = list(label_to_imgs.keys())\n",
    "\n",
    "        self.valid_pairs = [lbl for lbl in self.labels if len(self.label_to_imgs[lbl]) >= 2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_pairs) * 10\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_label = random.choice(self.valid_pairs)\n",
    "\n",
    "        anchor_path, positive_path = random.sample(self.label_to_imgs[anchor_label], 2)\n",
    "\n",
    "        negative_candidates = [l for l in self.valid_pairs if l != anchor_label]\n",
    "        negative_label = random.choice(negative_candidates)\n",
    "        negative_path = random.choice(self.label_to_imgs[negative_label])\n",
    "\n",
    "        try:\n",
    "            anchor_img = self.load_and_transform(anchor_path)\n",
    "            positive_img = self.load_and_transform(positive_path)\n",
    "            negative_img = self.load_and_transform(negative_path)\n",
    "\n",
    "            if (anchor_img is None) or (positive_img is None) or (negative_img is None):\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "            return anchor_img, positive_img, negative_img\n",
    "\n",
    "        except:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "    def load_and_transform(self, img_path):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_schedule(epoch, initial_margin=INITIAL_MARGIN, peak_margin=PEAK_MARGIN, final_margin=FINAL_MARGIN, peak_epoch=15, total_epochs=N_EPOCHS_MARGIN):\n",
    "    #peak margin was 0.6 in GOOD RUN now 0.8\n",
    "    if epoch < peak_epoch:\n",
    "        return initial_margin + (peak_margin - initial_margin) * (epoch / peak_epoch)  # Gradual increase\n",
    "    else:\n",
    "        return peak_margin - ((peak_margin - final_margin) * ((epoch - peak_epoch) / (total_epochs - peak_epoch)))  # Then refine\n",
    "    \n",
    "def cosine_sim_loss(anchor_embs, positive_embs):\n",
    "    return 1 - F.cosine_similarity(anchor_embs, positive_embs).mean()\n",
    "  \n",
    "def semi_hard_triplet_loss(anchor_embs, positive_embs, negative_embs, margin=MARGIN):\n",
    "    \n",
    "    d_ap = F.pairwise_distance(anchor_embs, positive_embs)  \n",
    "    d_an = F.pairwise_distance(anchor_embs, negative_embs)  \n",
    "\n",
    "    semi_hard_mask = (d_an > d_ap) & (d_an < (d_ap + margin))\n",
    "\n",
    "    if not semi_hard_mask.any():\n",
    "        losses = F.relu(d_ap - d_an + margin)\n",
    "        return losses.mean()\n",
    "\n",
    "    losses = F.relu(d_ap[semi_hard_mask] - d_an[semi_hard_mask] + margin)\n",
    "    return losses.mean()\n",
    "\n",
    "def hard_triplet_loss(anchor_embs, positive_embs, negative_embs, margin=MARGIN):\n",
    "    d_ap = F.pairwise_distance(anchor_embs, positive_embs)\n",
    "    d_an = F.pairwise_distance(anchor_embs, negative_embs)\n",
    "    \n",
    "    hard_mask = d_an < d_ap\n",
    "    \n",
    "    \n",
    "    if not hard_mask.any():\n",
    "        losses = F.relu(d_ap - d_an + margin)\n",
    "        return losses.mean()\n",
    "    \n",
    "    losses = F.relu(d_ap[hard_mask] - d_an[hard_mask] + margin)\n",
    "    return losses.mean()\n",
    "  \n",
    "def hybrid_triplet_loss(anchor_embs, positive_embs, negative_embs, epoch, margin = MARGIN, alpha = ALPHA):\n",
    "  d_an = F.pairwise_distance(anchor_embs,negative_embs)\n",
    "  d_ap = F.pairwise_distance(anchor_embs,positive_embs)\n",
    "    \n",
    "  margin = margin_schedule(epoch)\n",
    "\n",
    "  hard_mask = d_an < d_ap\n",
    "\n",
    "  semi_hard_mask = (d_an > d_ap) & (d_an < (d_ap + margin))\n",
    "  \n",
    "  hard_loss = None\n",
    "  semi_loss = None\n",
    "  if hard_mask.any():\n",
    "    hard_loss = F.relu(d_ap[hard_mask] - d_an[hard_mask] + margin)\n",
    "    hard_loss = hard_loss.mean()\n",
    "    \n",
    "  if semi_hard_mask.any():\n",
    "    semi_loss = F.relu(d_ap[semi_hard_mask] - d_an[semi_hard_mask] + margin)  \n",
    "    semi_loss = semi_loss.mean()\n",
    "    \n",
    "  base_loss = 0.0\n",
    "  if hard_loss is not None and semi_loss is not None:\n",
    "    base_loss = alpha * hard_loss + (1 - alpha) * semi_loss\n",
    "    \n",
    "  elif hard_loss is not None:\n",
    "    base_loss = hard_loss\n",
    "    \n",
    "  elif semi_loss is not None:\n",
    "    base_loss = semi_loss\n",
    "\n",
    "  else:\n",
    "    base_loss = F.relu(d_ap - d_an + margin).mean()\n",
    "  \n",
    "  cosine_weight = 0.25 if epoch > 10 else 0.0\n",
    "  return base_loss + cosine_weight * cosine_sim_loss(anchor_embs,positive_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerificationModel(nn.Module):\n",
    "    def __init__(self, backbone, embedding_size=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self._freeze_layers()\n",
    "      \n",
    "        in_features = self.backbone.fc.in_features  \n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.embedding_layer = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, embedding_size),\n",
    "        )\n",
    "\n",
    "    def _freeze_layers(self):\n",
    "      \n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.backbone.layer4.parameters():\n",
    "            param.requires_grad = True  \n",
    "           \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        emb = self.embedding_layer(features)\n",
    "        return F.normalize(emb, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, path='./models/'+name+'_model.pth'):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, val_acc, model):\n",
    "      \n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            print(\"saved model\")\n",
    "\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            print(f\"saved model at loss : {val_loss:.4f} - Accuracy: {val_acc:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, loss_fn, scaler, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for step, (anchor_imgs, pos_imgs, neg_imgs) in enumerate(loader):\n",
    "        anchor_imgs = anchor_imgs.to(device)\n",
    "        pos_imgs = pos_imgs.to(device)\n",
    "        neg_imgs = neg_imgs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            anchor_embs = model(anchor_imgs)\n",
    "            pos_embs = model(pos_imgs)\n",
    "            neg_embs = model(neg_imgs)\n",
    "            loss = loss_fn(anchor_embs, pos_embs, neg_embs, epoch)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, loss_fn, device, epoch, threshold = 0.75):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_sim = []\n",
    "    all_labels = []\n",
    "\n",
    "    for (anchor_imgs, pos_imgs, neg_imgs) in loader:\n",
    "        anchor_imgs = anchor_imgs.to(device)\n",
    "        pos_imgs = pos_imgs.to(device)\n",
    "        neg_imgs = neg_imgs.to(device)\n",
    "\n",
    "        anchor_embs = model(anchor_imgs)\n",
    "        pos_embs = model(pos_imgs)\n",
    "        neg_embs = model(neg_imgs)\n",
    "\n",
    "        batch_loss = loss_fn(anchor_embs, pos_embs, neg_embs, epoch)\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        pos_sim = F.cosine_similarity(anchor_embs, pos_embs)\n",
    "        neg_sim = F.cosine_similarity(anchor_embs, neg_embs)\n",
    "        all_sim.extend(pos_sim.cpu().numpy())\n",
    "        all_labels.extend([1]*len(pos_sim))\n",
    "        all_sim.extend(neg_sim.cpu().numpy())\n",
    "        all_labels.extend([0]*len(neg_sim))\n",
    "\n",
    "    all_sim = np.array(all_sim)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    if threshold is None:\n",
    "        thresholds = np.linspace(-1, 1, 200)  \n",
    "        accuracies = [(all_sim > t) == all_labels for t in thresholds]\n",
    "        accuracies = [np.mean(acc) for acc in accuracies]\n",
    "        best_idx = np.argmax(accuracies)\n",
    "        threshold = thresholds[best_idx]\n",
    "        best_acc = accuracies[best_idx]\n",
    "    else:\n",
    "        best_acc = np.mean((all_sim > threshold) == all_labels)\n",
    "\n",
    "    return running_loss / len(loader), best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "        T.Resize((256, 256)),               \n",
    "        T.RandomCrop(224),     # Random crop\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomRotation(10),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation = 0.1),\n",
    "        T.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # More conservative\n",
    "        T.ToImage(),\n",
    "        T.ToDtype(torch.float32, scale=True),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),              \n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./data\"\n",
    "\n",
    "train_data_path = os.path.join(dataset_path,'train/train')\n",
    "test_data_path = os.path.join(dataset_path,'val/test')\n",
    "\n",
    "train_identities = get_all_identities(train_data_path)\n",
    "\n",
    "train_chosen_identities = get_portion_of_identities(train_identities,1)\n",
    "train_label_to_imgs = build_label_to_images(train_data_path,train_chosen_identities)\n",
    "\n",
    "test_identities = get_all_identities(test_data_path)\n",
    "test_label_to_imgs = build_label_to_images(test_data_path,test_identities)\n",
    "\n",
    "train_dataset = FaceVerificationDataset(train_label_to_imgs, train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE ,shuffle = True, num_workers = min(4, os.cpu_count() // 2))\n",
    "\n",
    "test_dataset = FaceVerificationDataset(test_label_to_imgs,test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, num_workers = min(4, os.cpu_count() // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = FaceVerificationModel(backbone, dropout=DROPOUT, embedding_size=EMB_DIM).to(device)\n",
    "\n",
    "loss_fn = hybrid_triplet_loss  \n",
    "early_stopping = EarlyStopping(patience=5,min_delta = 0.01)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.backbone.layer4.parameters(), \"lr\": 5e-5},\n",
    "    {\"params\": model.embedding_layer.parameters(), \"lr\": LR},\n",
    "], weight_decay=DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=FACTOR, patience=3)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = None\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, scaler, device, epoch)\n",
    "    val_loss, val_acc = validate(\n",
    "        model, test_loader, loss_fn, device,epoch, threshold = THRESHOLD\n",
    "    )\n",
    "    if epoch > 10:\n",
    "      early_stopping(val_loss, val_acc, model)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[-1]['lr']\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        'epoch': epoch,\n",
    "        'learning_rate': current_lr\n",
    "    })\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "      print(\"Early stopping triggered! Stopping training.\")\n",
    "      break\n",
    "\n",
    "wandb.log({'best_loss':early_stopping.best_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def build_label_to_imgs(root_dir):\n",
    "    \"\"\"\n",
    "    root_dir: path to the directory containing subfolders like 'n000001', 'n000009', etc.\n",
    "    \n",
    "    Returns a dictionary: { 'n000001': [path1, path2, ...], 'n000009': [...], ... }\n",
    "    \"\"\"\n",
    "    label_to_imgs = {}\n",
    "    for identity_folder in os.listdir(root_dir):\n",
    "        identity_path = os.path.join(root_dir, identity_folder)\n",
    "        \n",
    "        if os.path.isdir(identity_path):\n",
    "            image_filenames = os.listdir(identity_path)\n",
    "            \n",
    "            image_paths = [\n",
    "                os.path.join(identity_path, img_name)\n",
    "                for img_name in image_filenames\n",
    "                if img_name.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "            ]\n",
    "            \n",
    "            if len(image_paths) > 0:\n",
    "                label_to_imgs[identity_folder] = image_paths\n",
    "    return label_to_imgs\n",
    "\n",
    "import random\n",
    "\n",
    "def random_subset_label_dict(label_to_imgs, num_identities=10, max_imgs_per_identity=None):\n",
    "\n",
    "    all_identities = list(label_to_imgs.keys())\n",
    "    random.shuffle(all_identities)\n",
    "\n",
    "    chosen_identities = all_identities[:num_identities]\n",
    "\n",
    "    subset_dict = {}\n",
    "    for identity in chosen_identities:\n",
    "     \n",
    "        if identity in label_to_imgs:\n",
    "            paths = label_to_imgs[identity]\n",
    "            random.shuffle(paths)  \n",
    "            if max_imgs_per_identity is not None:\n",
    "                paths = paths[:max_imgs_per_identity]\n",
    "            subset_dict[identity] = paths\n",
    "\n",
    "    return subset_dict\n",
    "\n",
    "class TSNEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, label_to_imgs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        for label, image_paths in label_to_imgs.items():\n",
    "            for path in image_paths:\n",
    "                self.samples.append((path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "root_dir = \"./data/val/test\" \n",
    "label_to_imgs = build_label_to_imgs(root_dir)\n",
    "\n",
    "subset_dict = random_subset_label_dict(label_to_imgs, num_identities=10, max_imgs_per_identity=20)\n",
    "\n",
    "tsne_dataset = TSNEDataset(subset_dict, transform=test_transforms)\n",
    "model.load_state_dict(torch.load('./models/'+name+'_model.pth',map_location=device))\n",
    "\n",
    "tsne_dataloader = DataLoader(tsne_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)  \n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "    import itertools\n",
    "    all_labels = list(itertools.chain(*all_labels))\n",
    "    all_labels = np.array(all_labels)\n",
    "    return all_embeddings, all_labels\n",
    "\n",
    "embeddings, labels = extract_embeddings(model, tsne_dataloader, device)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_and_log_tsne(embeddings, labels, perplexity=30, artifact_name=\"tsne_plots\"):\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    reduced = tsne.fit_transform(embeddings)\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    numeric_labels = np.array([label_to_index[label] for label in labels])\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    scatter = plt.scatter(\n",
    "        reduced[:, 0], \n",
    "        reduced[:, 1], \n",
    "        c=numeric_labels, \n",
    "        cmap=\"viridis\", \n",
    "        alpha=0.7\n",
    "    )\n",
    "    cbar = plt.colorbar(scatter, ticks=range(len(unique_labels)))\n",
    "    cbar.ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    plt.title(\"t-SNE Visualization of Face Embeddings\")\n",
    "    plt.xlabel(\"t-SNE Dim 1\")\n",
    "    plt.ylabel(\"t-SNE Dim 2\")\n",
    "\n",
    "    plot_filename = \"./tsneplots/tsne_plot\"+name+\".png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "    \n",
    "    artifact = wandb.Artifact(artifact_name, type=\"analysis\")\n",
    "    artifact.add_file(plot_filename)\n",
    "\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    wandb.log({\"tsne_plot\": wandb.Image(plot_filename)})\n",
    "\n",
    "\n",
    "\n",
    "plot_and_log_tsne(embeddings, labels, perplexity=40, artifact_name=\"tsne_\"+name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "\n",
    "positive_similarities = []\n",
    "negative_similarities = []\n",
    "\n",
    "for label, img_paths in label_to_imgs.items():\n",
    "    if len(img_paths) < 2:\n",
    "        continue\n",
    "    img1, img2 = random.sample(img_paths, 2)\n",
    "    emb1 = get_embedding(img1, model, test_transforms, device) \n",
    "    emb2 = get_embedding(img2, model, test_transforms, device)\n",
    "    pos_sim = F.cosine_similarity(torch.tensor(emb1).unsqueeze(0), torch.tensor(emb2).unsqueeze(0)).item()\n",
    "    positive_similarities.append(pos_sim)\n",
    "\n",
    "all_labels = list(label_to_imgs.keys())\n",
    "num_negatives = len(positive_similarities) \n",
    "for _ in range(num_negatives):\n",
    "    label1, label2 = random.sample(all_labels, 2)\n",
    "    img1 = random.choice(label_to_imgs[label1])\n",
    "    img2 = random.choice(label_to_imgs[label2])\n",
    "    emb1 = get_embedding(img1, model, test_transforms, device)\n",
    "    emb2 = get_embedding(img2, model, test_transforms, device)\n",
    "    neg_sim = F.cosine_similarity(torch.tensor(emb1).unsqueeze(0), torch.tensor(emb2).unsqueeze(0)).item()\n",
    "    negative_similarities.append(neg_sim)\n",
    "\n",
    "similarities = np.concatenate([np.array(positive_similarities), np.array(negative_similarities)])\n",
    "true_labels = np.concatenate([np.ones(len(positive_similarities)), np.zeros(len(negative_similarities))])\n",
    "\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_thresh = 0.0\n",
    "best_acc = 0.0\n",
    "acc_list = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    preds = similarities > thresh\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    acc_list.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"Optimal threshold: {:.2f} with accuracy: {:.2f}\".format(best_thresh, best_acc))\n",
    "\n",
    "pred_labels = similarities > best_thresh\n",
    "\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "fp = np.sum((pred_labels == 1) & (true_labels == 0))\n",
    "tn = np.sum((pred_labels == 0) & (true_labels == 0))\n",
    "fn = np.sum((pred_labels == 0) & (true_labels == 1))\n",
    "tp = np.sum((pred_labels == 1) & (true_labels == 1))\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "fpr_curve, tpr_curve, _ = roc_curve(true_labels, similarities, pos_label=1)\n",
    "roc_auc = auc(fpr_curve, tpr_curve)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    'best_threshold': best_thresh,\n",
    "    'best_thresh_acc': best_acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'FPR': fpr,\n",
    "    'FNR': fnr,\n",
    "    'ROC_AUC': roc_auc\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_curve, tpr_curve, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Face Verification (Cosine Similarity)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, acc_list, color='blue', label='Accuracy')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Threshold (Cosine Similarity)')\n",
    "plt.axvline(x=best_thresh, color='red', linestyle='--', label=f\"Best threshold: {best_thresh:.2f}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plot_filename = \"./ROCplots/ROC_CURVE\"+name+\".png\"\n",
    "plt.savefig(plot_filename)\n",
    "plt.close()\n",
    "\n",
    "wandb.log({'best_threshold': best_thresh, 'best_thresh_acc': best_acc})\n",
    "\n",
    "artifact = wandb.Artifact(\"roc_plots\", type=\"analysis\")\n",
    "artifact.add_file(plot_filename)\n",
    "\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "wandb.log({\"tsne_plot\": wandb.Image(plot_filename)})\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenetcorrect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
